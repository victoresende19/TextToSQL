# ü§ñ Agente de Chat com Banco de Dados
    Converse com seus dados em linguagem natural usando o poder da Intelig√™ncia Artificial.

Este projeto √© uma aplica√ß√£o web completa que permite a usu√°rios n√£o-t√©cnicos fazerem perguntas complexas a um banco de dados (como SQLite, SQL Server, PostgreSQL, etc.) usando apenas a linguagem do dia a dia. A IA traduz a pergunta em uma consulta SQL, executa no banco e devolve a resposta de forma clara e compreens√≠vel.

![alt text](image.png)

# ‚ú® Funcionalidades Principais
- **Interface de Chat Intuitiva:** Uma interface de chat moderna e responsiva constru√≠da com React e TypeScript.
- **Configura√ß√£o Din√¢mica:** Um modal de configura√ß√£o permite que o usu√°rio conecte a aplica√ß√£o a qualquer banco de dados suportado pelo SQLAlchemy, sem precisar alterar o c√≥digo.
- **Tradu√ß√£o de Linguagem Natural para SQL:** Utiliza um modelo de linguagem avan√ßado (LLM) para converter perguntas como "Qual cliente comprou mais teclados?" em consultas SQL v√°lidas.
- **Suporte a M√∫ltiplos Bancos:** Gra√ßas ao SQLAlchemy, a aplica√ß√£o √© compat√≠vel com diversos sistemas de banco de dados.
- **Gerenciamento de Contexto:** A conversa possui mem√≥ria e capacidade de resumir intera√ß√µes longas para otimizar o desempenho e economizar tokens.

# üõ†Ô∏è Tecnologias Utilizadas
- Backend:
    - Python
    - FastAPI
    - Langgraph
    - OpenAI
    - ChormaDB
    - SQLAlchemy
- Frontend:
    - TypeScript
    - React
    - Vite


# üìã Pr√©-requisitos
Antes de come√ßar, garanta que voc√™ tenha os seguintes softwares instalados:

- **Python 3.9+**
- **Node.js 18+** e **npm**
- Uma **chave de API da OpenAI**
- Acesso a um banco de dados (ex: um arquivo SQLite ou credenciais para um servidor SQL Server, PostgreSQL, etc.)

# ‚öôÔ∏è Instala√ß√£o e Execu√ß√£o
O projeto √© dividido em duas partes: Backend (servidor FastAPI) e Frontend (aplica√ß√£o React). Voc√™ precisar√° de dois terminais para execut√°-los simultaneamente.

1. Backend (Servidor FastAPI)

    a. Clone o reposit√≥rio e prepare o ambiente:
    ```
    # Ambiente virtual
    python -m venv venv
    source venv/bin/activate  # No Windows: venv\Scripts\activate

    # Instale as bibliotecas
    pip install requirements.txt
    ```

    b. Configure sua chave de API:
    Crie um arquivo chamado .env na raiz da pasta backend e adicione sua chave da OpenAI:
    ```
    OPENAI_API_KEY="sk-sua-chave-aqui"
    ```

    c. Execute o servidor:
    ```
    uvicorn main:app --reload
    ```
    O backend estar√° rodando em http://127.0.0.1:8000.

2. Frontend (Aplica√ß√£o React)

    a. Navegue at√© a pasta do frontend e instale as depend√™ncias:
    ```
    # Em um novo terminal
    cd ../frontend
    npm install
    ```

    b. Configure sua URL da API:
    Crie um arquivo chamado .env na raiz da pasta chat-frontend e adicione sua URL da API backend:
    ```
    VITE_API_BASE_URL=http://127.0.0.1:8000
    ```

    c. Execute a aplica√ß√£o:
    ```
    npm run dev
    ```
    O frontend estar√° acess√≠vel em http://localhost:5173 (ou outra porta indicada no terminal).

# üìñ Como Usar
- **Acesse a Aplica√ß√£o:** Abra seu navegador e acesse a URL do frontend (ex: http://localhost:5173).
- **P√°gina de Boas-Vindas:** Voc√™ ver√° uma p√°gina explicando o projeto. Clique no bot√£o "Configurar Base de Dados".
- **Configure o Agente:** Um modal aparecer√°. Preencha os seguintes campos:
    - **Dialeto do SQLAlchemy:** O dialeto espec√≠fico para o seu banco (ex: sqlite, mssql+pyodbc).
    - **String de Conex√£o:** A string de conex√£o completa do seu banco de dados.
    - **Tabelas para Consulta:** Adicione o nome e uma boa descri√ß√£o para cada tabela que a IA deve ser capaz de consultar. A qualidade da descri√ß√£o impacta diretamente a performance da IA.
- **Inicie o Chat:** Clique em "Iniciar Chat". Se a conex√£o com o banco for bem-sucedida, o modal se fechar√°.
- **Converse com seus Dados:** A interface de chat ser√° carregada. Voc√™ ver√° as tabelas configuradas no cabe√ßalho e uma mensagem de boas-vindas. Agora √© s√≥ fazer suas perguntas!

Obs.: A aplica√ß√£o ja possui dados de exemplo. Dessa forma voc√™ pode testar de maneira simples.
- **Exemplo:** "Qual cliente da cidade de S√£o Paulo gastou mais no total?"
- **Exemplo:** "Liste os 5 produtos mais vendidos no √∫ltimo m√™s."

# Fluxo Agente
O processo √© dividido em duas fases principais: a Configura√ß√£o, que ocorre uma vez, e a Execu√ß√£o da Pergunta, que ocorre a cada nova mensagem do usu√°rio.

**Fase 1 - Configura√ß√£o e Indexa√ß√£o da Base de Conhecimento**
Esta fase √© executada quando o endpoint ```/configure_agent``` √© chamado com a configura√ß√£o final. O objetivo √© preparar o contexto para o agente.

1. **Entrada do Usu√°rio:**
    - O sistema recebe as credenciais do banco de dados e uma lista de tabelas de interesse, cada uma com um nome e uma descri√ß√£o textual fornecida pelo usu√°rio.

2. **Extra√ß√£o de Schema:**
   - O backend conecta-se ao banco de dados especificado. Para cada tabela na lista de interesse, ele extrai o schema t√©cnico completo (a estrutura ```CREATE TABLE``` com todas as colunas e seus tipos de dados).

3. **Vetoriza√ß√£o (Embedding):**
   - Para cada tabela, a **descri√ß√£o** em texto fornecida pelo usu√°rio √© enviada a um modelo de embedding (ex: ```text-embedding-3-small``` da OpenAI). Este modelo converte a descri√ß√£o em um vetor (uma representa√ß√£o num√©rica de seu significado sem√¢ntico).

4. **Indexa√ß√£o no Banco Vetorial:**
   - O vetor gerado √© armazenado em uma cole√ß√£o do ChromaDB em mem√≥ria. O nome da tabela e seu schema t√©cnico completo s√£o armazenados como **metadata**, diretamente associados a esse vetor, mas sem serem vetorizados.

Ao final desta fase, o sistema possui um √≠ndice de busca sem√¢ntica em mem√≥ria, onde cada descri√ß√£o de tabela √© representada por um vetor e est√° vinculada ao seu schema t√©cnico.


**Fase 2 - Execu√ß√£o de uma Pergunta**
Este fluxo √© executado a cada chamada ao endpoint ```/query```.

1. **Roteamento de Tabelas (```Route Tables```):**
    - A pergunta do usu√°rio (ex: "Qual ano teve mais terremotos?") √© convertida em um vetor usando o mesmo modelo de embedding.
    - O ChromaDB realiza uma busca por **similaridade sem√¢ntica** (dist√¢ncia de cosseno), comparando o vetor da pergunta com os vetores das descri√ß√µes das tabelas j√° indexadas.
    - As ```N``` tabelas mais semanticamente relevantes s√£o identificadas. Os **metadados** dessas tabelas (incluindo seus schemas) s√£o recuperados.

2. **Gera√ß√£o de SQL (```Generate SQL```):**
    - Os schemas das tabelas recuperadas na etapa anterior s√£o combinados com a pergunta original do usu√°rio para formar um prompt de contexto.
    - Este prompt √© enviado a um Large Language Model (LLM) com a instru√ß√£o de gerar uma √∫nica e sintaticamente correta query SQL para responder √† pergunta.

3. **Execu√ß√£o de SQL (```Execute SQL```):**
    - A query SQL gerada pelo LLM √© executada diretamente no banco de dados de destino atrav√©s do SQLAlchemy.
    - Esta abordagem garante um resultado determin√≠stico e otimiza o uso da janela de contexto, pois evita passar grandes volumes de dados brutos da tabela para o LLM. O resultado da query √© retornado para o pr√≥ximo passo.

4. **Valida√ß√£o de Relev√¢ncia (```Validate Relevance```):**
    - O resultado da query, a query SQL e a pergunta original s√£o enviados a um LLM para uma valida√ß√£o.
    - A IA verifica se o resultado obtido √© uma resposta l√≥gica e relevante para a pergunta feita. Em caso de falha, o processo pode retornar √† etapa de Gera√ß√£o de SQL para uma nova tentativa (configurado para um m√°ximo de 3 tentativas).

5. **Gera√ß√£o da Resposta Final (```Generate Final Answer```):**
    - Ap√≥s a valida√ß√£o, o resultado da query SQL e a pergunta original s√£o enviados ao LLM.
    - A tarefa final do modelo √© sintetizar esses dados brutos em uma resposta coesa e em linguagem natural para ser apresentada ao usu√°rio.


![alt text](image-1.png)
